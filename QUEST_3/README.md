# AIFFEL Campus Online 5th Code Peer Review
- 코더 : 김민식
- 리뷰어 : 박혜원


# PRT(PeerReviewTemplate)
각 항목을 스스로 확인하고 토의하여 작성한 코드에 적용합니다.

- [O] 코드가 정상적으로 동작하고 주어진 문제를 해결했나요?
  > 언급해주신, '특이사항'으로 인해 셀별 Output 을 확인할 수 없었던 부분말고는 정상적으로 동작하였습니다. 
  (다만, 평가 문항 3번의 Score는 달성하지 못한 것으로 확인하였습니다.)
- [O] 주석을 보고 작성자의 코드가 이해되었나요?
  > 주석을 상세하게 달아주셔서 이해하기 쉬웠습니다. 
- [O] 코드가 에러를 유발할 가능성이 없나요?
  > 실행 해본 결과 모두 오류없이 작동하는것을 확인했습니다
- [O] 코드 작성자가 코드를 제대로 이해하고 작성했나요?
  > 네 상세한 주석과, 노드 학습 기반의 내용으로 작성된 것을 확인 할 수 있었습니다. 
- [O] 코드가 간결한가요?
  > 네 my_GridSearch 등 각 함수를 간결하고 명료하게 작성해주셨습니다. 

# 개선 사항 제안 
"# xgboost 관련 하이퍼 파라미터 준비" 부분에서 두 가지 파라미터만 조정해주셨는데, 다른 파라미터들도 추가하여 조정하면 더 성능이 좋은 모델을 생성할 수 있지 않았을까 싶어서 제안해봅니다. 

```python
# xgboost 관련 하이퍼 파라미터 준비
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [1, 5, 10],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'reg_alpha': [0, 0.1, 0.5],
    'reg_lambda': [0, 0.1, 1.0],
}


```



# 참고 링크 및 코드 개선
(GPT 의 도움을 받았습니다.)
위의 코드에서 추가된 파라미터들은 다음과 같습니다:

    learning_rate: 학습 속도를 조절하는 파라미터로, 0과 1 사이의 값이며 기본값은 0.3입니다. 작은 값을 선택할수록 학습이 더욱 느려지지만 더 정확한 예측 결과를 얻을 수 있습니다.
    subsample: 각 트리마다 사용할 훈련 데이터의 비율입니다. 기본값은 1.0으로, 모든 훈련 데이터를 사용합니다. 작은 값(0.6 또는 0.8)을 선택하면 트리가 다양한 부분집합의 데이터에 노출되어 모델의 과적합을 줄일 수 있습니다.
    colsample_bytree: 각 트리마다 사용할 특성(feature)의 비율입니다. 기본값은 1.0으로, 모든 특성을 사용합니다. 작은 값(0.6 또는 0.8)을 선택하면 트리가 다양한 부분집합의 특성에 노출되어 모델의 다양성을 높일 수 있습니다.
    reg_alpha와 reg_lambda: L1 (Lasso) 및 L2 (Ridge) 정규화(regularization)를 위한 가중치입니다. 0보다 큰 값을 선택하면 트리가 보다 일반화된 예측을 수행하도록 도와줍니다.


